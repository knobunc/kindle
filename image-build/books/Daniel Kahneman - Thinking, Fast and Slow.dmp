$VAR1 = [
          [
            1,
            '[ap 04:08] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_006.html) - 408',
            "You experienced slow thinking as you proceeded through a sequence of steps. You first retrieved from memory the cognitive program for multiplication that you learned in school, then you implemented it. Carrying out the computation was a strain. You felt the burden of holding much material in memory, as you needed to keep track of where you were and of where you were going, while holding on to the intermediate result. The process was mental work: deliberate, effortful, and orderly\x{2014}a prototype of slow thinking. The computation was not only an event in your mind; your body was also involved. Your muscles tensed up, your blood pressure rose, and your heart rate increased. Someone looking closely at your eyes while you tackled this problem would have seen your pupils dilate. Your pupils contracted back to normal size as soon as you ended your work\x{2014}when you found the answer (which is <<408|9c:0>>, by the way) or when you gave up.",
          ],
          [
            1,
            '[~ 20:00] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_010.html) - Around 1960',
            '<<Around 1960|9:0>>, a young psychologist named Sarnoff Mednick thought he had identified the essence of creativity. His idea was as simple as it was powerful: creativity is associative memory that works exceptionally well. He made up a test, called the Remote Association Test (RAT), which is still often used in studies of creativity.',
          ],
          [
            1,
            '[ap 01:56] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_017.html) - 1.56',
            "A related statistical fact is relevant to the cancer example. From the same urn, two very patient marble counters that\x{440}y dake turns. Jack draws 4 marbles on each trial, Jill draws 7. They both record each time they observe a homogeneous sample\x{2014}all white or all red. If they go on long enough, Jack will observe such extreme outcomes more often than Jill\x{2014}by a factor of 8 (the expected percentages are 12.5% and <<1.56|5a:0>>%). Again, no hammer, no causation, but a mathematical fact: samples of 4 marbles yield extreme results more often than samples of 7 marbles do.",
          ],
          [
            1,
            '[ap 01:44] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_018.html) - 144',
            "Did you produce your estimate by adjusting down from <<144|9c:0>>? Probably not, but the absurdly high number still affected your estimate. My hunch was that anchoring is a case of suggestion. This is the word we use when someone causes us to see, hear, or feel something by merely bringing it to mind. For example, the question \x{201c}Do you now feel a slight numbness in your left leg?\x{201d} always prompts quite a few people to report that their left leg does indeed feel a little strange.",
          ],
          [
            1,
            '[ap ~ 10:00] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_022.html) - About ten',
            "<<About ten|9:0>> questionnaires had accumulated in a tray on my assistant\x{2019}s desk before I casually glanced at them and found that all the subjects had ranked \x{201c}feminist bank teller\x{201d} as more probable than \x{201c}bank teller.\x{201d} I was so surprised that I still retain a \x{201c}flashbulb memory\x{201d} of the gray color of the metal desk and of where everyone was when I made that discovery. I quickly called Amos in great excitement to tell him what we had found: we had pitted logic against representativeness, and representativeness had won!",
          ],
          [
            1,
            '[ap 00:55] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_039.html) - 5 to 1',
            "The psychologist Paul Rozin, an expert on disgust, observed that a single cockroach will completely wreck the appeal of a bowl of cherries, but a cherry will do nothing at all for a bowl of cockroaches. As he points out, the negative trumps the positive in many ways, and loss aversion is one of many manifestations of a broad negativity dominance. Other scholars, in a paper titled \x{201c}Bad Is Stronger Than Good,\x{201d} summarized the evidence as follows: \x{201c}Bad emotions, bad parents, and bad feedback have more impact than good ones, and bad information is processed more thoroughly than good. The self is more motivated to avoid bad self-definitions than to pursue good ones. Bad impressions and bad stereotypes are quicker to form and more resistant to disconfirmation than good ones.\x{201d} They cite John Gottman, the well-known expert in marital relations, who observed that the long-term success of a relationship depends far more on avoiding the negative than on seeking the positive. Gottman estimated that a stable relationship requires Brro Qres Brrthat good interactions outnumber bad interactions by at least <<5 to 1|10a:1>>. Other asymmetries in the social domain are even more striking. We all know that a friendship that may take years to develop can be ruined by a single action.",
          ],
          [
            1,
            '[ap 09:59] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_041.html) - 1 of 10',
            "As you might expect, the remarkably foolish choices that people make in this situation have attracted the attention of many researchers. The bias has been given several names; following Paul Slovic I will call it denominator neglect. If your attention is drawn to the winning marbles, you do not assess the number of nonwinning marbles with the same care. Vivid imagery contributes to denominator neglect, at least as I experience it. When I think of the small urn, I see a single red marble on a vaguely defined background of white marbles. When I think of the larger urn, I see eight winning red marbles on an indistinct background of white marbles, which creates a more hopeful feeling. The distinctive vividness of the winning marbles increases the decision weight of that event, enhancing the possibility effect. Of course, the same will be true of the certainty effect. If I have a 90% chance of winning a prize, the event of not winning will be more salient if 10 of 100 marbles are \x{201c}losers\x{201d} than if <<1 of 10|10>> marbles yields the same outcome.",
          ],
          [
            1,
            '[15:00] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_043.html) - 15',
            "The survey of parents\x{2019} reactions to a potentially hazardous insecticide mentioned earlier also included a question about the willingness to accept increased risk. The respondents were told to imagine that they used an insecticide where the risk of inhalation and child poisoning was 15 per 10,000 bottles. A less expensive insecticide was available, for which the risk rose from <<15|20b>> to <<16|20a>> per 10,000 bottles. The parents were asked for the discount that would induce them to switch to the less expensive (and less safe) product. More than two-thirds of the parents in the survey responded that they would not purchase the new product at any price! They were evidently revolted by the very idea of trading the safety of their child for money. The minority who found a discount they could accept demanded an amount that was significantly higher than the amount they were willing to pay for a far larger improvement in the safety of the product.",
          ],
          [
            1,
            '[13:48] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_045.html) - 12 to 14',
            "Suppose both drivers travel equal distances over a year. Who will save more gas by switching? You almost certainly share the widespread intuition that Beth\x{2019}s action is more significant than Adam\x{2019}s: she reduced mpg by 10 miles rather than 2, and by a third (from 30 to 40) rather than a sixth (from <<12 to 14|10a:0>>). Now engage your System 2 and work it out. If the two car owners both drive 10,000 miles, Adam will reduce his consumption from a scandalous 833 gallons to a still shocking 714 gallons, for a saving of 119 gallons. Beth\x{2019}s use of fuel will drop from 333 gallons to 250, saving only 83 gallons. The mpg frame is wrong, and it should be replaced by the gallons-per-mile frame (or liters-per\x{2013}100 kilometers, which is used in most other countries). As Larrick and Soll point out, the misleading intuitions fostered by the mpg frame are likely to mislead policy makers as well as car buyers.",
          ],
          [
            1,
            '[20:00] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_048.html) - 20',
            'My fascination with the possible discrepancies between experienced utility and decision utility goes back a long way. While Amos and I were still working on prospect theory, I formulated a puzzle, which went like this: imagine an individual who receives one painful injection every day. There is no adaptation; the pain is the same day to day. Will people attach the same value to reducing the number of planned injections from <<20|20b>> to <<18|20a>> as from <<6|20b>> to <<4|20a>>? Is there any justification for a distinction?',
          ],
          [
            1,
            '[ap 03:54] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_048.html) - 6 to 4',
            'I did not collect data, because the outcome was evident. You can verify for yourself that you would pay more to reduce the number of injections by a third (from <<6 to 4|10a:0>>) than by one tenth (from <<20 to 18|10a:0>>). The decision utility of avoiding two injections is higher in the first case than in the second, and everyone will pay more for the first reduction than for the second. But this difference is absurd. If the pain does not change from day to day, what could justify assigning different utilities to a reduction of the total amount of pain by two injections, depending on the number of previous injections? In the terms we would use today, the puzzle introduced the idea that experienced utility could be measured by the number of injections. It also suggested that, at least in some cases, experienced utility is the criterion by which a decision should be assessed. A decision maker who pays different amounts to achieve the same gain of experienced utility (or be spared the same loss) is making a mistake. You may find this observation obvious, but in decision theory the only basis for judging that a decision is wrong is inconsistency with other preferences. Amos and I discussed the problem but we did not pursue it. Many years later, I returned to it.',
          ],
          [
            1,
            '[20:00] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_048.html) - 20',
            'The most useful idea in the injections puzzle that preoccupied me years ago was that the experienced utility of a series of equally painful injections can be measured, by simply counting the injections. If all injections are equally aversive, then 20 of them are twice as bad as 10, and Jon e oe e a reduction from <<20|20b>> to <<18|20a>> and a reduction from <<6|20b>> to <<4|20a>> are equally valuable. If the decision utility does not correspond to the experienced utility, then something is wrong with the decision. The same logic played out in the cold-hand experiment: an episode of pain that lasts 90 seconds is worse than the first 60 seconds of that episode. If people willingly choose to endure the longer episode, something is wrong with their decision. In my early puzzle, the discrepancy between the decision and the experience originated from diminishing sensitivity: the difference between 18 and 20 is less impressive, and appears to be worth less, than the difference between 6 and 4 injections. In the cold-hand experiment, the error reflects two principles of memory: duration neglect and the peak-end rule. The mechanisms are different but the outcome is the same: a decision that is not correctly attuned to the experience.',
          ],
          [
            1,
            '[ap 05:44] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_053.html) - 5.44',
            "Insensitivity to prior probability of outcomes. One of the factors that have no effect on representativeness but should have a major effect on probability is the prior probability, or base rate frequency, of the outcomes. In the case of Steve, for example, the fact that there are many more farmers than librarians in the population should enter into any reasonable estimate of the probability that Steve is a librarian rather than a farmer. Considerations of base-rate frequency, however, do not affect the similarity of Steve to the stereotypes of librarians and farmers. If people evaluate probability by representativeness, therefore, prior probabilities will be neglected. This hypothesis was tested in an experiment where prior probabilities were manipulated. Subjects were shown brief personality descriptions of several individuals, allegedly sampled at random from a group of 100 professionals\x{2014}engineers and lawyers. The subjects were asked to assess, for each description, the probability that it belonged to an engineer rather than to a lawy [hanerser. In one experimental condition, subjects were told that the group from which the descriptions had been drawn consisted of 70 engineers and 30 lawyers. In another condition, subjects were told that the group consisted of 30 engineers and 70 lawyers. The odds that any particular description belongs to an engineer rather than to a lawyer should be higher in the first condition, where there is a majority of engineers, than in the second condition, where there is a majority of lawyers. Specifically, it can be shown by applying Bayes\x{2019} rule that the ratio of these odds should be (.7/.3), or <<5.44|5a:0>>, for each description. In a sharp violation of Bayes\x{2019} rule, the subjects in the two conditions produced essentially the same probability judgments. Apparently, subjects evaluated the likelihood that a particular description belonged to an engineer rather than to a lawyer by the degree to which this description was representative of the two stereotypes, with little or no regard for the prior probabilities of the categories.",
          ],
          [
            1,
            '[23:58] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_055.html) - 2 to 0',
            "A closely related phenomenon can be demonstrated at the low end of the probability range. Suppose you are undecided whether or not to purchase earthquake insurance because the premium is quite high. As you hesitate, your friendly insurance agent comes forth with an alternative offer: \x{201c}For half the regular premium you can be fully covered if the quake occurs on an odd day of the month. This is a good deal because for half the price you are covered for more than half the days.\x{201d} Why do most people find such probabilistic insurance distinctly unattractive? Figure 2 suggests an answer. Starting anywhere in the region of low probabilities, the impact on the decision weight of a reduction of probability from p to p/2 is considerably smaller than the effect of a reduction from p/<<2 to 0|10a:0>>. Reducing the risk by half, then, is not worth half the premium.",
          ],
          [
            1,
            "[23:36] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_055.html) - 23\x{2013}36",
            "Bernoulli, D. 1954 [1738]. \x{201c}Exposition of a New Theory on the Measurement of Risk.\x{201d} Econometrica 22: <<23\x{2013}36|5a:0>>.",
          ],
          [
            1,
            "[21:36] Thinking, Fast and Slow - Daniel Kahneman.epub (CR!TA0Q4JDFX96QN90P9V64BBTEV4QG_split_055.html) - 21\x{2013}36",
            "Slovic, P., B. Fischhoff, and S. Lichtenstein. 1982. \x{201c}Response Mode, Framing, and InformationProcessing Effects in Risk Assessment.\x{201d} In New Directions for Methodology of Social and Behavioral Science: Question Framing and Response Consistency, ed. R. Hogarth. San Francisco: Jossey-Bass, <<21\x{2013}36|5a:0>>.",
          ],
        ];
